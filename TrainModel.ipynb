{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "URyAH6DV88vt"
      },
      "source": [
        "# import the necessary packages"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc9TA3fh9u3j",
        "outputId": "28bfc220-eb36-4502-d9ff-c66bf6efeef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXZdGNCx88vy"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "import os \n",
        "import pandas as pd\n",
        "\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfrDT4mJ88v2"
      },
      "source": [
        "# Learning rate, epochs and batches "
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UjYCNgU88v6"
      },
      "source": [
        "initLayer = 1e-4\n",
        "epochs = 70\n",
        "batch = 32"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeWhBqyf_PNF"
      },
      "source": [
        "df = pd.read_csv ('/content/gdrive/My Drive/age_gender.csv')\n",
        "import os\n",
        "import os.path\n",
        "import csv\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Ethnicity labels\n",
        "ETHNICITIES = { \n",
        "    0: \"White\", \n",
        "    1: \"Black\",\n",
        "    2: \"Asian\",\n",
        "    3: \"Indian\",\n",
        "    4: \"Hispanic\"\n",
        "}\n",
        "\n",
        "# Gender labels\n",
        "GENDERS = { \n",
        "    0: \"Male\", \n",
        "    1: \"Female\"\n",
        "}\n",
        "\n",
        "AGES = {\n",
        "    0: \"Child\",\n",
        "    1: \"Teen\",\n",
        "    2: \"Young_Adult\",\n",
        "    3: \"Adult\",\n",
        "    4: \"Elderly\"\n",
        "}\n",
        "\n",
        "\n",
        "# Directory to store the images\n",
        "base_path = os.path.join(os.path.curdir, 'images')\n",
        "labeled_paths = {}\n",
        "if not os.path.isdir(base_path):\n",
        "    os.makedirs(base_path)\n",
        "\n",
        "# Sort images in directories by ethnicity then gender\n",
        "# ToDo: Add ages labes and directories \n",
        "for ek, ev in ETHNICITIES.items():\n",
        "    for ak, av in AGES.items():\n",
        "        for gk, gv in GENDERS.items():     \n",
        "            labeled_path = os.path.join(base_path, ev, av, gv)\n",
        "            if (gk == 0):\n",
        "                labeled_paths.setdefault(ek,{})[ak] = {0: \"\", 1: \"\"}\n",
        "            labeled_paths.setdefault(ek,{})[ak][gk] = labeled_path\n",
        "            if not os.path.isdir(labeled_path):\n",
        "                os.makedirs(labeled_path)\n",
        "\n",
        "\n",
        "    # Read dataset as dict entries\n",
        "csv_reader = csv.DictReader(df)\n",
        "\n",
        "with open('/content/gdrive/My Drive/age_gender.csv',\"r\") as fp:\n",
        "    # Read dataset as dict entries\n",
        "    csv_reader = csv.DictReader(fp)\n",
        "\n",
        "    for row in csv_reader:\n",
        "        age = int(row['age'])\n",
        "        ethnicity = int(row['ethnicity'])\n",
        "        gender = int(row['gender'])\n",
        "\n",
        "        ageLabel = \"\"\n",
        "\n",
        "        if age > 61:\n",
        "            ageLabel = 4\n",
        "        elif age > 21:\n",
        "            ageLabel = 3\n",
        "        elif age > 18:\n",
        "            ageLabel = 2\n",
        "        elif age > 12:\n",
        "            ageLabel = 1\n",
        "        else: ageLabel = 0\n",
        "\n",
        "\n",
        "        # Extract pixel string (string list of grayscale integers sep by space)\n",
        "        pixels = bytearray([int(px) for px in row['pixels'].split(' ')])\n",
        "\n",
        "        # Create new Image of resolution 48*48 from pixels\n",
        "        #   I assumed a square image, so I computed\n",
        "        #     len(pixels)**.5  # = 48.0\n",
        "        #   to get the resolution.\n",
        "        img = Image.frombytes('L', (48,48), bytes(pixels))\n",
        "\n",
        "        # Name of file to write to\n",
        "        #file_name = row['img_name']\n",
        "        # or name file with labels: age_ethnicity_gender-original.jpg\n",
        "        file_name = f\"{ageLabel}_{ethnicity}_{gender}-{row['img_name'].split('.')[0]}.jpg\"\n",
        "\n",
        "        # The path to save the image to\n",
        "        file_dir = labeled_paths.get(ethnicity, {}).get(ageLabel, {}).get( gender, base_path)\n",
        "        file_path = os.path.join(file_dir, file_name)\n",
        "\n",
        "        # Write out the Image file\n",
        "        img.save(file_path)\n",
        "        # or save without JPEG compression\n",
        "        #img.save(file_path + \".png\", 'png', compress_level=0)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVCZJq_m88v9"
      },
      "source": [
        "# getting files and initializing our data and labels array"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C35-0WhY88wB"
      },
      "source": [
        "directory = \"./images\"\n",
        "ethnicities = [\"Asian\", \"Black\", \"Hispanic\", \"Indian\", \"White\"]\n",
        "ages = [\"Child\", \"Teen\", \"Young_Adult\", \"Adult\", \"Elderly\"]\n",
        "genders = [\"Female\", \"Male\"]\n",
        "data = []\n",
        "labels = []\n",
        "label = 0\n",
        "for ethnicity in ethnicities:\n",
        "    for age in ages:\n",
        "        for gender in genders:\n",
        "            path = os.path.join(directory, ethnicity, age, gender)\n",
        "            \n",
        "            for img in os.listdir(path):\n",
        "                img_path = os.path.join(path, img)\n",
        "                image = load_img(img_path, target_size=(48, 48))\n",
        "                image = img_to_array(image)\n",
        "                image = preprocess_input(image)\n",
        "                data.append(image)\n",
        "                labels.append(label)\n",
        "            label += 1"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUdIYze188wE"
      },
      "source": [
        "# transforming our labels to categorical and then  to numpy array"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAHmMxFk88wI"
      },
      "source": [
        "labels = to_categorical(labels)\n",
        "data = np.array(data,dtype=\"float32\")\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDkXDW6v88wL",
        "outputId": "ce3df5e5-ae3b-42b5-b2a4-8cdaea92fc4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shekHp1I88wP",
        "outputId": "7bb6d185-3e78-4b86-deb3-217a2c5737d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(labels))\n",
        "print(len(labels[0]))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23607\n",
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdnScURS88wS"
      },
      "source": [
        "# partition the data into training and testing splits using 80% of\n",
        "# the data for training and the remaining 20% for testing"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChImuyfx88wW"
      },
      "source": [
        "(trainX,testX,trainY,testY) = train_test_split(data,labels,test_size=0.20,stratify=labels,random_state=20)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIRZJald88wZ"
      },
      "source": [
        "# initialize the training data augmentation object"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AybS4KME88wc"
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\")"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNxX48kI88wg"
      },
      "source": [
        "# initialize the validation/testing data augmentation object (which\n",
        "# we'll be adding mean subtraction to)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGwXZFVt88wj"
      },
      "source": [
        "valAug = ImageDataGenerator()"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrVZ05Am88wm"
      },
      "source": [
        "# define the ImageNet mean subtraction (in RGB order) and set the\n",
        "# the mean subtraction value for each of the data augmentation\n",
        "# objects"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOtdrWtE88wp"
      },
      "source": [
        "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
        "aug.mean = mean\n",
        "valAug.mean = mean"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEZ1AHFK88wt"
      },
      "source": [
        "# load RsdNet%0, ensuring the head FC layer sets are left off, while at\n",
        "# the same time adjusting the size of the input image tensor to the\n",
        "# network"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DbzG9H488wx"
      },
      "source": [
        "baseModel = ResNet50(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    classes=50,\n",
        "    input_tensor=Input(shape=(48, 48, 3))\n",
        ")"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5G3Mukd88w0"
      },
      "source": [
        "# show a summary of the base model"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwfl9r1z88w4",
        "outputId": "57924f47-0db0-46ec-a053-688f50835e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"[INFO] summary for base model...\")\n",
        "print(baseModel.summary())"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] summary for base model...\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 48, 48, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 54, 54, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 24, 24, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 24, 24, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 24, 24, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 26, 26, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 12, 12, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 12, 12, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 12, 12, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 12, 12, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 12, 12, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 12, 12, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 12, 12, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 12, 12, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 12, 12, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 12, 12, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 12, 12, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 12, 12, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 12, 12, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 12, 12, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 12, 12, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 12, 12, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 12, 12, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 12, 12, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 12, 12, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 12, 12, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 12, 12, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 12, 12, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 12, 12, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 12, 12, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 12, 12, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 12, 12, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 12, 12, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 12, 12, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 12, 12, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 12, 12, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 12, 12, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 12, 12, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 12, 12, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 6, 6, 128)    32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 6, 6, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 6, 6, 128)    147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 6, 6, 128)    0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 6, 6, 512)    131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 6, 6, 512)    66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 6, 6, 512)    2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 6, 6, 512)    2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 6, 6, 512)    0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 6, 6, 512)    0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 6, 6, 128)    65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 6, 6, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 6, 6, 128)    147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 6, 6, 128)    0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 6, 6, 512)    66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 6, 6, 512)    2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 6, 6, 512)    0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 6, 6, 512)    0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 6, 6, 128)    65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 6, 6, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 6, 6, 128)    147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 6, 6, 128)    0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 6, 6, 512)    66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 6, 6, 512)    2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 6, 6, 512)    0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 6, 6, 512)    0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 6, 6, 128)    65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 6, 6, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 6, 6, 128)    147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 6, 6, 128)    0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 6, 6, 512)    66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 6, 6, 512)    2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 6, 6, 512)    0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 6, 6, 512)    0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 3, 3, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 3, 3, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 3, 3, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 3, 3, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 3, 3, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 3, 3, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 3, 3, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 3, 3, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 3, 3, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 3, 3, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 3, 3, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 3, 3, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 3, 3, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 3, 3, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 3, 3, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 3, 3, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 3, 3, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 3, 3, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 3, 3, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 3, 3, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 3, 3, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 3, 3, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 3, 3, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 3, 3, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 3, 3, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 3, 3, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 3, 3, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 3, 3, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 3, 3, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 3, 3, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 3, 3, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 3, 3, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 3, 3, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 3, 3, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 3, 3, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 3, 3, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 3, 3, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 3, 3, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 3, 3, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 3, 3, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 3, 3, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 3, 3, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 3, 3, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 3, 3, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 3, 3, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 3, 3, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 3, 3, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 3, 3, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 3, 3, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 3, 3, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 2, 2, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 2, 2, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 2, 2, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 2, 2, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 2, 2, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 2, 2, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 2, 2, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 2, 2, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 2, 2, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 2, 2, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 2, 2, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 2, 2, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZdSIMcQ88w7"
      },
      "source": [
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wJAIdIa88xD"
      },
      "source": [
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(2, 2))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(50, activation=\"softmax\")(headModel)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJjvSiyf88xH"
      },
      "source": [
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqsuGS1g88xL"
      },
      "source": [
        "model = Model(inputs=baseModel.input, outputs=headModel)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5sYna5R88xU"
      },
      "source": [
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the first training process"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJDZBN_B88xY"
      },
      "source": [
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3b_B6Rj88xb"
      },
      "source": [
        "# compile our model (this needs to be done after our setting our\n",
        "# layers to being non-trainable)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF_3h5tM88xf",
        "outputId": "4a831732-0ef0-44bc-931c-daf9daf161db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=1e-4)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "    metrics=[\"accuracy\"])"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u-qfBih88xi"
      },
      "source": [
        "# train the head of the network for a few epochs (all other layers\n",
        "# are frozen) -- this will allow the new FC layers to start to become\n",
        "# initialized with actual \"learned\" values versus pure random"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4MD3akJ88xm",
        "outputId": "0da33283-b33d-41dd-aa87-f9ad19a6bf42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"[INFO] training head...\")\n",
        "H = model.fit(\n",
        "    x=aug.flow(trainX, trainY, batch_size=batch),\n",
        "    steps_per_epoch= 587,\n",
        "    validation_data=valAug.flow(testX, testY),\n",
        "    validation_steps= 140,\n",
        "    epochs=epochs)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training head...\n",
            "Epoch 1/70\n",
            "587/587 [==============================] - 20s 34ms/step - loss: 3.3714 - accuracy: 0.1178 - val_loss: 3.0958 - val_accuracy: 0.1763\n",
            "Epoch 2/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 3.1865 - accuracy: 0.1412 - val_loss: 3.0211 - val_accuracy: 0.1819\n",
            "Epoch 3/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 3.1271 - accuracy: 0.1500 - val_loss: 2.9849 - val_accuracy: 0.1893\n",
            "Epoch 4/70\n",
            "587/587 [==============================] - 19s 33ms/step - loss: 3.0864 - accuracy: 0.1575 - val_loss: 2.9612 - val_accuracy: 0.1882\n",
            "Epoch 5/70\n",
            "587/587 [==============================] - 19s 33ms/step - loss: 3.0512 - accuracy: 0.1644 - val_loss: 2.9311 - val_accuracy: 0.2009\n",
            "Epoch 6/70\n",
            "587/587 [==============================] - 19s 33ms/step - loss: 3.0290 - accuracy: 0.1718 - val_loss: 2.9160 - val_accuracy: 0.1991\n",
            "Epoch 7/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 3.0151 - accuracy: 0.1672 - val_loss: 2.8960 - val_accuracy: 0.1998\n",
            "Epoch 8/70\n",
            "587/587 [==============================] - 19s 33ms/step - loss: 2.9968 - accuracy: 0.1761 - val_loss: 2.8695 - val_accuracy: 0.2085\n",
            "Epoch 9/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.9778 - accuracy: 0.1789 - val_loss: 2.8604 - val_accuracy: 0.2098\n",
            "Epoch 10/70\n",
            "587/587 [==============================] - 19s 33ms/step - loss: 2.9661 - accuracy: 0.1781 - val_loss: 2.8593 - val_accuracy: 0.2134\n",
            "Epoch 11/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.9516 - accuracy: 0.1868 - val_loss: 2.8258 - val_accuracy: 0.2134\n",
            "Epoch 12/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.9432 - accuracy: 0.1843 - val_loss: 2.8123 - val_accuracy: 0.2174\n",
            "Epoch 13/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.9268 - accuracy: 0.1873 - val_loss: 2.8139 - val_accuracy: 0.2167\n",
            "Epoch 14/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.9297 - accuracy: 0.1871 - val_loss: 2.7934 - val_accuracy: 0.2243\n",
            "Epoch 15/70\n",
            "587/587 [==============================] - 19s 33ms/step - loss: 2.9128 - accuracy: 0.1936 - val_loss: 2.7769 - val_accuracy: 0.2281\n",
            "Epoch 16/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.9074 - accuracy: 0.1926 - val_loss: 2.7821 - val_accuracy: 0.2261\n",
            "Epoch 17/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.9002 - accuracy: 0.1919 - val_loss: 2.7611 - val_accuracy: 0.2290\n",
            "Epoch 18/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8920 - accuracy: 0.1941 - val_loss: 2.7605 - val_accuracy: 0.2248\n",
            "Epoch 19/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8824 - accuracy: 0.1972 - val_loss: 2.7658 - val_accuracy: 0.2241\n",
            "Epoch 20/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8775 - accuracy: 0.1987 - val_loss: 2.7506 - val_accuracy: 0.2292\n",
            "Epoch 21/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8783 - accuracy: 0.2018 - val_loss: 2.7454 - val_accuracy: 0.2281\n",
            "Epoch 22/70\n",
            "587/587 [==============================] - 19s 33ms/step - loss: 2.8691 - accuracy: 0.1984 - val_loss: 2.7406 - val_accuracy: 0.2346\n",
            "Epoch 23/70\n",
            "587/587 [==============================] - 19s 33ms/step - loss: 2.8652 - accuracy: 0.1993 - val_loss: 2.7213 - val_accuracy: 0.2368\n",
            "Epoch 24/70\n",
            "587/587 [==============================] - 19s 33ms/step - loss: 2.8613 - accuracy: 0.2034 - val_loss: 2.7147 - val_accuracy: 0.2411\n",
            "Epoch 25/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8540 - accuracy: 0.2044 - val_loss: 2.7102 - val_accuracy: 0.2431\n",
            "Epoch 26/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8418 - accuracy: 0.2069 - val_loss: 2.7064 - val_accuracy: 0.2420\n",
            "Epoch 27/70\n",
            "587/587 [==============================] - 19s 33ms/step - loss: 2.8451 - accuracy: 0.2094 - val_loss: 2.6849 - val_accuracy: 0.2473\n",
            "Epoch 28/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8416 - accuracy: 0.2081 - val_loss: 2.6887 - val_accuracy: 0.2460\n",
            "Epoch 29/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8381 - accuracy: 0.2085 - val_loss: 2.6930 - val_accuracy: 0.2467\n",
            "Epoch 30/70\n",
            "587/587 [==============================] - 19s 33ms/step - loss: 2.8304 - accuracy: 0.2086 - val_loss: 2.6777 - val_accuracy: 0.2482\n",
            "Epoch 31/70\n",
            "587/587 [==============================] - 19s 33ms/step - loss: 2.8333 - accuracy: 0.2077 - val_loss: 2.6690 - val_accuracy: 0.2525\n",
            "Epoch 32/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8318 - accuracy: 0.2102 - val_loss: 2.6934 - val_accuracy: 0.2413\n",
            "Epoch 33/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8230 - accuracy: 0.2108 - val_loss: 2.6759 - val_accuracy: 0.2480\n",
            "Epoch 34/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8263 - accuracy: 0.2097 - val_loss: 2.6897 - val_accuracy: 0.2442\n",
            "Epoch 35/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8224 - accuracy: 0.2156 - val_loss: 2.6774 - val_accuracy: 0.2446\n",
            "Epoch 36/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8143 - accuracy: 0.2128 - val_loss: 2.6579 - val_accuracy: 0.2491\n",
            "Epoch 37/70\n",
            "587/587 [==============================] - 19s 33ms/step - loss: 2.8113 - accuracy: 0.2130 - val_loss: 2.6488 - val_accuracy: 0.2489\n",
            "Epoch 38/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8027 - accuracy: 0.2163 - val_loss: 2.6570 - val_accuracy: 0.2475\n",
            "Epoch 39/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8062 - accuracy: 0.2110 - val_loss: 2.6523 - val_accuracy: 0.2507\n",
            "Epoch 40/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.8016 - accuracy: 0.2133 - val_loss: 2.6647 - val_accuracy: 0.2482\n",
            "Epoch 41/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7950 - accuracy: 0.2158 - val_loss: 2.6482 - val_accuracy: 0.2502\n",
            "Epoch 42/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.8048 - accuracy: 0.2120 - val_loss: 2.6557 - val_accuracy: 0.2496\n",
            "Epoch 43/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.8040 - accuracy: 0.2128 - val_loss: 2.6413 - val_accuracy: 0.2542\n",
            "Epoch 44/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.7961 - accuracy: 0.2183 - val_loss: 2.6261 - val_accuracy: 0.2562\n",
            "Epoch 45/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.7850 - accuracy: 0.2206 - val_loss: 2.6466 - val_accuracy: 0.2538\n",
            "Epoch 46/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7889 - accuracy: 0.2155 - val_loss: 2.6479 - val_accuracy: 0.2507\n",
            "Epoch 47/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7880 - accuracy: 0.2133 - val_loss: 2.6322 - val_accuracy: 0.2545\n",
            "Epoch 48/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7843 - accuracy: 0.2144 - val_loss: 2.6463 - val_accuracy: 0.2493\n",
            "Epoch 49/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7835 - accuracy: 0.2191 - val_loss: 2.6202 - val_accuracy: 0.2600\n",
            "Epoch 50/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7762 - accuracy: 0.2169 - val_loss: 2.6263 - val_accuracy: 0.2525\n",
            "Epoch 51/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7872 - accuracy: 0.2210 - val_loss: 2.6385 - val_accuracy: 0.2504\n",
            "Epoch 52/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7823 - accuracy: 0.2201 - val_loss: 2.6534 - val_accuracy: 0.2538\n",
            "Epoch 53/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7777 - accuracy: 0.2209 - val_loss: 2.6262 - val_accuracy: 0.2542\n",
            "Epoch 54/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7803 - accuracy: 0.2235 - val_loss: 2.6349 - val_accuracy: 0.2529\n",
            "Epoch 55/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7666 - accuracy: 0.2200 - val_loss: 2.6269 - val_accuracy: 0.2580\n",
            "Epoch 56/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7736 - accuracy: 0.2158 - val_loss: 2.6275 - val_accuracy: 0.2567\n",
            "Epoch 57/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7736 - accuracy: 0.2209 - val_loss: 2.6132 - val_accuracy: 0.2578\n",
            "Epoch 58/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7658 - accuracy: 0.2188 - val_loss: 2.6206 - val_accuracy: 0.2498\n",
            "Epoch 59/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7748 - accuracy: 0.2215 - val_loss: 2.6110 - val_accuracy: 0.2587\n",
            "Epoch 60/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7662 - accuracy: 0.2238 - val_loss: 2.6238 - val_accuracy: 0.2525\n",
            "Epoch 61/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7679 - accuracy: 0.2217 - val_loss: 2.5891 - val_accuracy: 0.2627\n",
            "Epoch 62/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7634 - accuracy: 0.2241 - val_loss: 2.6053 - val_accuracy: 0.2594\n",
            "Epoch 63/70\n",
            "587/587 [==============================] - 18s 31ms/step - loss: 2.7586 - accuracy: 0.2184 - val_loss: 2.6030 - val_accuracy: 0.2545\n",
            "Epoch 64/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.7615 - accuracy: 0.2250 - val_loss: 2.6047 - val_accuracy: 0.2585\n",
            "Epoch 65/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.7561 - accuracy: 0.2221 - val_loss: 2.6069 - val_accuracy: 0.2560\n",
            "Epoch 66/70\n",
            "587/587 [==============================] - 19s 33ms/step - loss: 2.7533 - accuracy: 0.2245 - val_loss: 2.6075 - val_accuracy: 0.2580\n",
            "Epoch 67/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.7525 - accuracy: 0.2267 - val_loss: 2.6162 - val_accuracy: 0.2529\n",
            "Epoch 68/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.7520 - accuracy: 0.2242 - val_loss: 2.6108 - val_accuracy: 0.2583\n",
            "Epoch 69/70\n",
            "587/587 [==============================] - 19s 32ms/step - loss: 2.7546 - accuracy: 0.2250 - val_loss: 2.5917 - val_accuracy: 0.2594\n",
            "Epoch 70/70\n",
            "587/587 [==============================] - 19s 33ms/step - loss: 2.7465 - accuracy: 0.2270 - val_loss: 2.5926 - val_accuracy: 0.2598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1BuXCn788xu"
      },
      "source": [
        "# plot the training loss and accuracy"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHvAZ78I88xz",
        "outputId": "b3ebe016-58c6-44e3-ed5a-df0f2d16b50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "N = epochs\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch 5\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"plot-\"+ str(epochs) + \"-\" + str(batch) + \".png\")"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kmc6ojM88x8"
      },
      "source": [
        "#Serialize the model to disk"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH9hoqvc88x_"
      },
      "source": [
        "model.save(\"/content/gdrive/My Drive/mask_detector.model\", save_format=\"h5\")"
      ],
      "execution_count": 114,
      "outputs": []
    }
  ]
}